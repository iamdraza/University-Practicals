{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Iris Species\n",
    "In this section, we will go through a simple machine learning application and create\n",
    "our first classification model. In the process, we will introduce some core concepts and terms.\n",
    "\n",
    "Let’s assume that a hobby botanist is interested in distinguishing the species of some\n",
    "iris flowers that she has found. She has collected some measurements associated with\n",
    "each iris: the length and width of the petals and the length and width of the sepals, all\n",
    "measured in centimeters.\n",
    "\n",
    "She also has the measurements of some irises that have been previously identified by\n",
    "an expert botanist as belonging to the species setosa, versicolor, or virginica. For these\n",
    "measurements, she can be certain of which species each iris belongs to. Let’s assume\n",
    "that these are the only species our hobby botanist will encounter in the wild.\n",
    "\n",
    "Our goal is to build a machine learning model that can learn from the measurements\n",
    "of these irises whose species is known, so that we can predict the species for a new\n",
    "iris.\n",
    "\n",
    "Reference: Introduction to Machine learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "The sklearn package provides some built-in real-world data sets to let users experience working on a real-world data analysis applications. The Iris data set is one of them. Please refer to https://scikit-learn.org/stable/datasets/index.html for more information about these built-in data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature names: \n",
      " ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "Target names: \n",
      " ['setosa' 'versicolor' 'virginica']\n",
      "Feature data size: \n",
      " (150, 4)\n",
      "Target data size: \n",
      " (150,)\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn import datasets\n",
    "\n",
    "iris_data = datasets.load_iris()\n",
    "\n",
    "print(\"Feature names: \\n\", iris_data.feature_names)\n",
    "print(\"Target names: \\n\", iris_data.target_names)\n",
    "\n",
    "print(\"Feature data size: \\n\", iris_data.data.shape)\n",
    "print(\"Target data size: \\n\", iris_data.target.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build a machine learning model from this data that can predict the species\n",
    "of iris for a new set of measurements. But before we can apply our model to new\n",
    "measurements, we need to know whether it actually works—that is, whether we\n",
    "should trust its predictions.\n",
    "\n",
    "To assess the model’s performance, we show it new data (data that it hasn’t seen\n",
    "before) for which we have labels. This is usually done by splitting the labeled data we\n",
    "have collected (here, our 150 flower measurements) into two parts. One part of the\n",
    "data is used to build our machine learning model, and is called the training data or\n",
    "training set. The rest of the data will be used to assess how well the model works; this\n",
    "is called the test data, test set, or hold-out set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn contains a function that shuffles the dataset and splits it for you: the\n",
    "[train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) function. As default, this function extracts 75% of the rows in the data as the\n",
    "training set, together with the corresponding labels for this data. The remaining 25%\n",
    "of the data, together with the remaining labels, is declared as the test set. Deciding\n",
    "how much data you want to put into the training and the test set respectively is somewhat\n",
    "arbitrary, but using a test set containing 25% of the data is a good rule of thumb.\n",
    "\n",
    "In scikit-learn, data is usually denoted with a capital X, while labels are denoted by\n",
    "a lowercase y. This is inspired by the standard formulation f(x)=y in mathematics,\n",
    "where x is the input to a function and y is the output. Following more conventions\n",
    "from mathematics, we use a capital X because the data is a two-dimensional array (a\n",
    "matrix) and a lowercase y because the target is a one-dimensional array (a vector).\n",
    "Let’s call train_test_split on our data and assign the outputs using this nomenclature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(iris_data['data'], iris_data['target'], random_state=142)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making the split, the train_test_split function shuffles the dataset using a\n",
    "pseudorandom number generator. If we just took the last 25% of the data as a test set,\n",
    "all the data points would have the label 2, as the data points are sorted by the label\n",
    "(see the output for iris['target'] shown earlier). Using a test set containing only\n",
    "one of the three classes would not tell us much about how well our model generalizes,\n",
    "so we shuffle our data to make sure the test data contains data from all classes.\n",
    "\n",
    "To make sure that we will get the same output if we run the same function several\n",
    "times, we provide the pseudorandom number generator with a fixed seed using the\n",
    "random_state parameter. This will make the outcome deterministic, so this line will\n",
    "always have the same outcome. We will always fix the random_state in this way when\n",
    "using randomized procedures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the train_test_split function is X_train, X_test, y_train, and\n",
    "y_test, which are all NumPy arrays. X_train contains 75% of the rows of the dataset,\n",
    "and X_test contains the remaining 25%:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (112, 4)\n",
      "y_train shape: (112,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: {}\".format(X_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test shape: (38, 4)\n",
      "y_test shape: (38,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test shape: {}\".format(X_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Nearest Neighbours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start building the actual machine learning model. There are many classification\n",
    "algorithms in scikit-learn that we could use. Here we will use a k-nearest\n",
    "neighbors classifier, which is easy to understand. Building this model only consists of\n",
    "storing the training set. To make a prediction for a new data point, the algorithm\n",
    "finds the point in the training set that is closest to the new point. Then it assigns the\n",
    "label of this training point to the new data point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All machine learning models in scikit-learn are implemented in their own classes,\n",
    "which are called Estimator classes. The k-nearest neighbors classification algorithm\n",
    "is implemented in the [KNeighborsClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier) class in the neighbors module. Before\n",
    "we can use the model, we need to instantiate the class into an object. This is when we\n",
    "will set any parameters of the model. The most important parameter of KNeighbors\n",
    "Classifier is the number of neighbors, which we will set to 1 for our first exploration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "2\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "3\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "4\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "5\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "6\n",
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2 12]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.95      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "7\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "8\n",
      "[[ 7  0  0]\n",
      " [ 0 17  0]\n",
      " [ 0  2 12]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      1.00      0.94        17\n",
      "           2       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.95      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "9\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "10\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "11\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "12\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "13\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "14\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "15\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "16\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "17\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  1 13]]\n",
      "0.9473684210526315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.94      0.94        17\n",
      "           2       0.93      0.93      0.93        14\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.96      0.96        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "18\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "19\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "20\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "21\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "22\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "23\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "24\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "25\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  2 12]]\n",
      "0.868421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.82      0.85        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.89      0.89      0.89        38\n",
      "weighted avg       0.87      0.87      0.87        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "26\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "27\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "28\n",
      "[[ 7  0  0]\n",
      " [ 0 16  1]\n",
      " [ 0  2 12]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.89      0.94      0.91        17\n",
      "           2       0.92      0.86      0.89        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.94      0.93      0.93        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "29\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "30\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "31\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "32\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "33\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "34\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "35\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "36\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "37\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "38\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "39\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "40\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "41\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "42\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "43\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "44\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "45\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "46\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "47\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n",
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "48\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  2 12]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.88      0.88      0.88        17\n",
      "           2       0.86      0.86      0.86        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.91      0.91      0.91        38\n",
      "weighted avg       0.89      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "49\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "50\n",
      "[[ 7  0  0]\n",
      " [ 0 15  2]\n",
      " [ 0  1 13]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9210526315789473\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.94      0.88      0.91        17\n",
      "           2       0.87      0.93      0.90        14\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.94      0.94        38\n",
      "weighted avg       0.92      0.92      0.92        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "51\n",
      "[[ 7  0  0]\n",
      " [ 0 14  3]\n",
      " [ 0  1 13]]\n",
      "0.8947368421052632\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       0.93      0.82      0.87        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.89        38\n",
      "   macro avg       0.92      0.92      0.91        38\n",
      "weighted avg       0.90      0.89      0.89        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "52\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  2 12]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.87      0.86        38\n",
      "weighted avg       0.84      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "53\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  2 12]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.87      0.86        38\n",
      "weighted avg       0.84      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "54\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  2 12]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.87      0.86        38\n",
      "weighted avg       0.84      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "55\n",
      "[[ 7  0  0]\n",
      " [ 1 12  4]\n",
      " [ 0  1 13]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.92      0.71      0.80        17\n",
      "           2       0.76      0.93      0.84        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.88      0.86        38\n",
      "weighted avg       0.86      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "56\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  2 12]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.87      0.86        38\n",
      "weighted avg       0.84      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "57\n",
      "[[ 7  0  0]\n",
      " [ 1 12  4]\n",
      " [ 0  2 12]]\n",
      "0.8157894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.71      0.77        17\n",
      "           2       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.83      0.85      0.84        38\n",
      "weighted avg       0.82      0.82      0.81        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "58\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  2 12]]\n",
      "0.8421052631578947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.87      0.76      0.81        17\n",
      "           2       0.80      0.86      0.83        14\n",
      "\n",
      "    accuracy                           0.84        38\n",
      "   macro avg       0.85      0.87      0.86        38\n",
      "weighted avg       0.84      0.84      0.84        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "59\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  1 13]]\n",
      "0.868421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.93      0.76      0.84        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.87      0.90      0.88        38\n",
      "weighted avg       0.88      0.87      0.87        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "60\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  4 10]]\n",
      "0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.76      0.76      0.76        17\n",
      "           2       0.77      0.71      0.74        14\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.80      0.83      0.81        38\n",
      "weighted avg       0.79      0.79      0.79        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "61\n",
      "[[ 7  0  0]\n",
      " [ 1 13  3]\n",
      " [ 0  1 13]]\n",
      "0.868421052631579\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.93      0.76      0.84        17\n",
      "           2       0.81      0.93      0.87        14\n",
      "\n",
      "    accuracy                           0.87        38\n",
      "   macro avg       0.87      0.90      0.88        38\n",
      "weighted avg       0.88      0.87      0.87        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "62\n",
      "[[ 7  0  0]\n",
      " [ 1 14  2]\n",
      " [ 0  5  9]]\n",
      "0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.74      0.82      0.78        17\n",
      "           2       0.82      0.64      0.72        14\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.81      0.82      0.81        38\n",
      "weighted avg       0.79      0.79      0.79        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "63\n",
      "[[ 7  0  0]\n",
      " [ 1  9  7]\n",
      " [ 0  1 13]]\n",
      "0.7631578947368421\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.90      0.53      0.67        17\n",
      "           2       0.65      0.93      0.76        14\n",
      "\n",
      "    accuracy                           0.76        38\n",
      "   macro avg       0.81      0.82      0.79        38\n",
      "weighted avg       0.80      0.76      0.75        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "64\n",
      "[[ 7  0  0]\n",
      " [ 1 14  2]\n",
      " [ 0  5  9]]\n",
      "0.7894736842105263\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.74      0.82      0.78        17\n",
      "           2       0.82      0.64      0.72        14\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.81      0.82      0.81        38\n",
      "weighted avg       0.79      0.79      0.79        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "65\n",
      "[[ 7  0  0]\n",
      " [ 1 14  2]\n",
      " [ 0  4 10]]\n",
      "0.8157894736842105\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.78      0.82      0.80        17\n",
      "           2       0.83      0.71      0.77        14\n",
      "\n",
      "    accuracy                           0.82        38\n",
      "   macro avg       0.83      0.85      0.83        38\n",
      "weighted avg       0.82      0.82      0.81        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "66\n",
      "[[ 7  0  0]\n",
      " [ 1 14  2]\n",
      " [ 0  5  9]]\n",
      "0.7894736842105263\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.74      0.82      0.78        17\n",
      "           2       0.82      0.64      0.72        14\n",
      "\n",
      "    accuracy                           0.79        38\n",
      "   macro avg       0.81      0.82      0.81        38\n",
      "weighted avg       0.79      0.79      0.79        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "67\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "68\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "69\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "70\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "71\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "72\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "73\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "74\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "75\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "76\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "77\n",
      "[[ 7  0  0]\n",
      " [ 1  6 10]\n",
      " [ 0  1 13]]\n",
      "0.6842105263157895\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       0.86      0.35      0.50        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.68        38\n",
      "   macro avg       0.77      0.76      0.71        38\n",
      "weighted avg       0.75      0.68      0.65        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "78\n",
      "[[ 7  0  0]\n",
      " [ 2  5 10]\n",
      " [ 0  1 13]]\n",
      "0.6578947368421053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88         7\n",
      "           1       0.83      0.29      0.43        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.73      0.74      0.67        38\n",
      "weighted avg       0.72      0.66      0.61        38\n",
      "\n",
      "________________________________________________________________________________\n",
      "79\n",
      "[[ 7  0  0]\n",
      " [ 2  5 10]\n",
      " [ 0  1 13]]\n",
      "0.6578947368421053\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88         7\n",
      "           1       0.83      0.29      0.43        17\n",
      "           2       0.57      0.93      0.70        14\n",
      "\n",
      "    accuracy                           0.66        38\n",
      "   macro avg       0.73      0.74      0.67        38\n",
      "weighted avg       0.72      0.66      0.61        38\n",
      "\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "accuracies = []\n",
    "for i in range(1, 80):\n",
    "    clf = KNeighborsClassifier(n_neighbors=i)\n",
    "    clf.fit(X_train, Y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracies.append(accuracy_score(Y_test, y_pred))\n",
    "    print(i)\n",
    "    print(confusion_matrix(Y_test, y_pred))\n",
    "    print(accuracy_score(Y_test, y_pred))\n",
    "    print(classification_report(Y_test, y_pred))\n",
    "    print('_'*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build the model on the training set, we call the fit method of the knn object,\n",
    "which takes as arguments the NumPy array X_train containing the training data and\n",
    "the NumPy array y_train of the corresponding training labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fd64ddd688>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(accuracies, columns=['ACC']).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now make predictions using this model on new data for which we might not\n",
    "know the correct labels. Imagine we found an iris in the wild with a sepal length of\n",
    "5 cm, a sepal width of 2.9 cm, a petal length of 1 cm, and a petal width of 0.2 cm.\n",
    "What species of iris would this be? We can put this data into a NumPy array, again by\n",
    "calculating the shape—that is, the number of samples (1) multiplied by the number of\n",
    "features (4):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_new.shape: (1, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_new = np.array([[5, 2.9, 1, 0.2]])\n",
    "print(\"X_new.shape: {}\".format(X_new.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=1, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the result label of X_new:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [0]\n",
      "predicted target name: ['setosa']\n"
     ]
    }
   ],
   "source": [
    "prediction = knn.predict(X_new)\n",
    "print(\"Prediction:\", prediction)\n",
    "print(\"predicted target name:\", iris_data['target_names'][prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model predicts that this new iris belongs to the class 0, meaning its species is\n",
    "setosa. But how do we know whether we can trust our model? We don’t know the correct\n",
    "species of this sample, which is the whole point of building the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where the test set that we created earlier comes in. This data was not used to\n",
    "build the model, but we do know what the correct species is for each iris in the test\n",
    "set. So, we can use the trained model to predict these data instances and calculate the [accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) to evaluate how good the model is."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set Predictions:\n",
      " [0 1 1 2 1 1 0 0 2 1 1 1 2 0 2 0 2 1 1 1 2 1 0 1 2 1 2 2 0 1 2 1 2 1 2 2 1\n",
      " 2]\n",
      "Test set score: 0.89\n",
      "Test set score: 0.89\n"
     ]
    }
   ],
   "source": [
    "y_pred = knn.predict(X_test)\n",
    "print(\"Test set Predictions:\\n\", y_pred)\n",
    "print(\"Test set score: {:.2f}\".format(np.mean(y_pred == Y_test)))\n",
    "print(\"Test set score: {:.2f}\".format(knn.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Tuning with Cross Validation (CV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we’ll explore a CV method that can be used to tune the hyperparameter K using the above training and test data.\n",
    "\n",
    "Scikit-learn comes in handy with its [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html#sklearn.model_selection.cross_val_score) method. We specifiy that we are performing 10 folds with the cv=10 parameter and that our scoring metric should be accuracy since we are in a classification setting. In each iteration, the training data take 90% of the total data while testing data takes 10%. The average on the accuracies reported from each iteration will make the testing accuracy more robust than just a single split of the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "cv_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for each round: \n",
      " [1.         0.93333333 1.         1.         1.         0.86666667\n",
      " 0.93333333 0.93333333 1.         1.        ]\n",
      "Average accuracy: 0.9667 +- 0.0447\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors = 10)\n",
    "scores = cross_val_score(clf, X, y, cv=10)\n",
    "print('Accuracy for each round: \\n', scores)\n",
    "print('Average accuracy: %.4f +- %.4f' % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the misclassification error versus K. You need to figure out the possible values of K. If the number of possible values is too big, you can take some values with a certain step, e.g., K = 1, 5, 10, ... with a step of 5. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkpoint 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal number of neighbors is 36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "neighbors = list(range(1, 50, 5))\n",
    "cv_scores = []\n",
    "\n",
    "# perform 10-fold cross validation\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "    \n",
    "mse = [1 - x for x in cv_scores]\n",
    "\n",
    "# determining best k\n",
    "optimal_k = neighbors[mse.index(min(mse))]\n",
    "print(\"The optimal number of neighbors is {}\".format(optimal_k))\n",
    "\n",
    "# plot misclassification error vs k\n",
    "plt.plot(neighbors, mse)\n",
    "plt.xlabel(\"Number of Neighbors K\")\n",
    "plt.ylabel(\"Misclassification Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the [GridSearch](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV) method to accomplish automatic model selection. Check against the figure plotted above to see if the selected hyperparameter K can lead to the lowest misclassification error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best K value:  13\n",
      "The accuracy:  0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "# Define search space for parameters\n",
    "parameter_grid = {'n_neighbors': range(1, 41)}\n",
    "\n",
    "# Create the machine learning model\n",
    "knn_clf = KNeighborsClassifier()\n",
    "clf = GridSearchCV(knn_clf, parameter_grid, scoring='accuracy', cv=10)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# Identify the best parameter\n",
    "print('Best K value: ', clf.best_params_['n_neighbors'])\n",
    "print('The accuracy: ', clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
